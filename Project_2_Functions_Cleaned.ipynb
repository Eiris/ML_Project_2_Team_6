{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "\n",
    "# Load image data\n",
    "data_load_1 = sio.loadmat('Proj2FeatVecsSet1.mat')\n",
    "data_load_2 = sio.loadmat('Proj2TargetOutputsSet1.mat')\n",
    "data_set = data_load_1['Proj2FeatVecsSet1']\n",
    "data_target = data_load_2['Proj2TargetOutputsSet1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide my target data into nice 1-D classifier\n",
    "number_labels = []\n",
    "for ars in data_target:\n",
    "    if np.all(ars == [1,-1,-1,-1,-1]):\n",
    "        ars = 1\n",
    "        number_labels.append(ars)\n",
    "    elif np.all(ars == [-1,1,-1,-1,-1]):\n",
    "        ars = 2\n",
    "        number_labels.append(ars)\n",
    "    elif np.all(ars == [-1,-1,1,-1,-1]):\n",
    "        ars = 3\n",
    "        number_labels.append(ars)\n",
    "    elif np.all(ars == [-1,-1,-1,1,-1]):\n",
    "        ars = 4\n",
    "        number_labels.append(ars)\n",
    "    elif np.all(ars == [-1,-1,-1,-1,1]):\n",
    "        ars = 5\n",
    "        number_labels.append(ars)\n",
    "        \n",
    "number_labels = np.asarray(number_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define how many components we should use and run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(data_set)\n",
    "cum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "eigenvalues = pca.explained_variance_\n",
    "\n",
    "count = 0\n",
    "for var in cum_var:\n",
    "    count += 1\n",
    "    if var >= 0.95:\n",
    "        n_components = count\n",
    "#         answer = \"We need about \"+ str(n_components) + \" components to retain 95% of the variance\"\n",
    "#         print(answer)\n",
    "        break\n",
    "        \n",
    "# plt.figure(1)\n",
    "# plt.plot(cum_var)\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Cumulative Explained Variance')\n",
    "# plt.figure(2)\n",
    "# plt.plot(eigenvalues)\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Eigenvalues')\n",
    "# plt.show()\n",
    "\n",
    "# Minumum Noise Factor --> Similar to PCA but removes noise from bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from skimage.transform import rescale\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#Using PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "reduced_data = pca.fit_transform(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Data Folds - Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# #############################################################################\n",
    "# Split into a training set and a test set using a stratified k fold\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    reduced_data, number_labels, test_size=0.20, stratify = number_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data breakdown - For X_train_1 and y_train_1, take sample of 1000 out of 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be done nicely with the kfold function\n",
    "X_train_1 = X_train[:1000]\n",
    "X_train_2 = X_train[5000:9999]\n",
    "X_train_3 = X_train[10000:14999]\n",
    "X_train_4 = X_train[15000:20000]\n",
    "y_train_1 = y_train[:1000]\n",
    "y_train_2 = y_train[5000:9999]\n",
    "y_train_3 = y_train[10000:14999]\n",
    "y_train_4 = y_train[15000:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainMyClassifierParameters Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainMyClassifierParameters(Algorithm):\n",
    "    if Algorithm == 'SVM':\n",
    "        Parameters = {\n",
    "            'C' : 0.1,\n",
    "            'gamma' : 0.1\n",
    "        }\n",
    "    elif Algorithm == 'RVM':\n",
    "        Parameters = {\n",
    "            'alpha' : 1e-06,\n",
    "            'beta' : 1e-06\n",
    "        }\n",
    "    elif Algorithm == 'GP':\n",
    "        Parameters = {\n",
    "            'length_scale' : 10             \n",
    "        }\n",
    "    return Parameters, Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainMyClassifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure if this is the correct type of function we need\n",
    "def TrainMyClassifier(XEstimate, YEstimate, XValidate, TrainMyClassifierParameters):\n",
    "    from sklearn.svm import SVC\n",
    "    from skrvm import RVC\n",
    "    from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "    from sklearn.multiclass import OneVsOneClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.gaussian_process.kernels import RBF\n",
    "    from time import time\n",
    "    t0 = time()\n",
    "    # Paramaters should have this shape in order for it to work ==>  Parameters = {'C': [1e3, 1e4, 1e5], 'gamma': [0.001, 0.01, 0.1] }\n",
    "    if TrainMyClassifierParameters[1] == 'SVM':\n",
    "        # ################################################\n",
    "        # Train a SVM classification model\n",
    "        print(\"Fitting the classifier to the training set\")\n",
    "        param_grid = TrainMyClassifierParameters[0]\n",
    "        clf = SVC(kernel='rbf', class_weight='balanced', decision_function_shape = 'ovo',**TrainMyClassifierParameters[0])\n",
    "        clf = clf.fit(XEstimate, YEstimate)\n",
    "        y_pred = clf.predict(XValidate)\n",
    "        scores = clf.score(XEstimate,YEstimate)\n",
    "        params = clf\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        return y_pred, scores, params\n",
    "    elif TrainMyClassifierParameters[1] == 'RVM':\n",
    "        # #############################################################################\n",
    "        # Train a RVM classification model\n",
    "        print(\"Fitting the classifier to the training set\")\n",
    "        t0 = time()\n",
    "        clf = RVC(kernel='rbf',n_iter=1,**TrainMyClassifierParameters[0])\n",
    "        clf.fit(XEstimate, YEstimate)\n",
    "        y_pred = clf.predict(XValidate)\n",
    "        scores = clf.score(XEstimate,YEstimate)\n",
    "        params = clf\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        return y_pred, scores, params\n",
    "    elif TrainMyClassifierParameters[1] == 'GP':\n",
    "       # #############################################################################\n",
    "        # Train a GP classification model\n",
    "        print(\"Fitting the classifier to the training set\")\n",
    "        t0 = time()\n",
    "        k_rbf = 1 * RBF(length_scale=TrainMyClassifierParameters[0]['length_scale'])\n",
    "        clf = GaussianProcessClassifier(kernel = k_rbf, multi_class = 'one_vs_one')\n",
    "        clf.fit(X_train_1, y_train_1)\n",
    "        y_pred = clf.predict(XValidate)\n",
    "        scores = clf.score(XEstimate,YEstimate)\n",
    "        params = clf\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        return y_pred, scores, params\n",
    "    else:\n",
    "        print(\"Incorrect type of algorithm, please use only one of the supported classifiers SVM, RVM, GP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "done in 9.650s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3, 2, 5, ..., 2, 1, 5]),\n",
       " 0.948,\n",
       " RVC(alpha=1e-06, beta=1e-06, beta_fixed=False, bias_used=True, coef0=0.0,\n",
       "   coef1=None, degree=3, kernel='rbf', n_iter=1, n_iter_posterior=50,\n",
       "   threshold_alpha=1000000000.0, tol=0.001, verbose=False))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = TrainMyClassifier(X_train_1, y_train_1, X_test,TrainMyClassifierParameters('RVM'))\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyConfusionMatrix Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyConfusionMatrix(Y,YValidate,ClassNames):\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import pandas as pd\n",
    "    c_r = classification_report(YValidate, Y)\n",
    "    c_m = confusion_matrix(YValidate, Y)\n",
    "    a_s = accuracy_score(YValidate, Y)\n",
    "    # labels = ['One','Two','Three','Four','Five'] - This is the format of the labels\n",
    "    labels = ClassNames\n",
    "    df = pd.DataFrame(c_m, dtype='str', index=labels)\n",
    "    df.columns = ClassNames\n",
    "    return c_m, df, a_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[966,  15,  20,   6,   3],\n",
       "        [ 13, 901,   5,  95,   2],\n",
       "        [  3,   6, 932,   5,  31],\n",
       "        [  5,  72,   6, 855,  23],\n",
       "        [ 13,   6,  37,  39, 941]], dtype=int64),\n",
       "        One  Two Three Four Five\n",
       " One    966   15    20    6    3\n",
       " Two     13  901     5   95    2\n",
       " Three    3    6   932    5   31\n",
       " Four     5   72     6  855   23\n",
       " Five    13    6    37   39  941,\n",
       " 0.919)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyConfusionMatrix(y_test, test[0],['One','Two','Three','Four','Five'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyCrossValidate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyCrossValidate(XTrain,YTrain2,Nf,Algorithm): #Why do we use a YTrain with '2' index?\n",
    "    # This function goes here\n",
    "    return YTrain, EstParameters, EstConfMatrices, ConfMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TestMyClassifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestMyClassifier(XTest, Parameters, EstParameters):\n",
    "    # Do similar to trainmyclassifer but with the data from MyCrossValidation\n",
    "    return YTest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
