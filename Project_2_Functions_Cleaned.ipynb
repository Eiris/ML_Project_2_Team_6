{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "\n",
    "# Load image data\n",
    "data_load_1 = sio.loadmat('Proj2FeatVecsSet1.mat')\n",
    "data_load_2 = sio.loadmat('Proj2TargetOutputsSet1.mat')\n",
    "data_set = data_load_1['Proj2FeatVecsSet1']\n",
    "data_target = data_load_2['Proj2TargetOutputsSet1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide my target data into nice 1-D classifier\n",
    "number_labels = []\n",
    "for ars in data_target:\n",
    "    if np.all(ars == [1,-1,-1,-1,-1]):\n",
    "        ars = 1\n",
    "        number_labels.append(ars)\n",
    "    elif np.all(ars == [-1,1,-1,-1,-1]):\n",
    "        ars = 2\n",
    "        number_labels.append(ars)\n",
    "    elif np.all(ars == [-1,-1,1,-1,-1]):\n",
    "        ars = 3\n",
    "        number_labels.append(ars)\n",
    "    elif np.all(ars == [-1,-1,-1,1,-1]):\n",
    "        ars = 4\n",
    "        number_labels.append(ars)\n",
    "    elif np.all(ars == [-1,-1,-1,-1,1]):\n",
    "        ars = 5\n",
    "        number_labels.append(ars)\n",
    "        \n",
    "number_labels = np.asarray(number_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define how many components we should use and run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(data_set)\n",
    "cum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "eigenvalues = pca.explained_variance_\n",
    "\n",
    "count = 0\n",
    "for var in cum_var:\n",
    "    count += 1\n",
    "    if var >= 0.95:\n",
    "        n_components = count\n",
    "#         answer = \"We need about \"+ str(n_components) + \" components to retain 95% of the variance\"\n",
    "#         print(answer)\n",
    "        break\n",
    "        \n",
    "# plt.figure(1)\n",
    "# plt.plot(cum_var)\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Cumulative Explained Variance')\n",
    "# plt.figure(2)\n",
    "# plt.plot(eigenvalues)\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Eigenvalues')\n",
    "# plt.show()\n",
    "\n",
    "# Minumum Noise Factor --> Similar to PCA but removes noise from bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from skimage.transform import rescale\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#Using PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "reduced_data = pca.fit_transform(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Data Folds - Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# #############################################################################\n",
    "# Split into a training set and a test set using a stratified k fold\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    reduced_data, number_labels, test_size=0.20, stratify = number_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data breakdown - For X_train_1 and y_train_1, take sample of 1000 out of 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be done nicely with the kfold function\n",
    "X_train_1 = X_train[:1000]\n",
    "X_train_2 = X_train[5000:9999]\n",
    "X_train_3 = X_train[10000:14999]\n",
    "X_train_4 = X_train[15000:20000]\n",
    "y_train_1 = y_train[:1000]\n",
    "y_train_2 = y_train[5000:9999]\n",
    "y_train_3 = y_train[10000:14999]\n",
    "y_train_4 = y_train[15000:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainMyClassifierParameters Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainMyClassifierParameters(Algorithm):\n",
    "    if Algorithm == 'SVM':\n",
    "        Parameters = {\n",
    "            'C' : [0.1],\n",
    "            'gamma' : [0.1]\n",
    "        }\n",
    "    elif Algorithm == 'RVM':\n",
    "        Parameters = {\n",
    "            'alpha' : [1e-06],\n",
    "            'beta' : [1e-06]\n",
    "        }\n",
    "    elif Algorithm == 'GP':\n",
    "        Parameters = {\n",
    "            'length_scale' : [1]             \n",
    "        }\n",
    "    return Parameters, Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainMyClassifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure if this is the correct type of function we need\n",
    "def TrainMyClassifier(XEstimate, YEstimate, XValidate, TrainMyClassifierParameters):\n",
    "    from sklearn.svm import SVC\n",
    "    from skrvm import RVC\n",
    "    from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "    from sklearn.multiclass import OneVsOneClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.gaussian_process.kernels import RBF\n",
    "    from time import time\n",
    "    t0 = time()\n",
    "    # Paramaters should have this shape in order for it to work ==>  Parameters = {'C': [1e3, 1e4, 1e5], 'gamma': [0.001, 0.01, 0.1] }\n",
    "    if TrainMyClassifierParameters[1] == 'SVM':\n",
    "        # ################################################\n",
    "        # Train a SVM classification model\n",
    "        print(\"Fitting the classifier to the training set\")\n",
    "        param_grid = TrainMyClassifierParameters[0]\n",
    "        clf = OneVsOneClassifier(GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid))\n",
    "        clf = clf.fit(XEstimate, YEstimate)\n",
    "        y_pred = clf.predict(XValidate)\n",
    "        scores = clf.score(XEstimate,YEstimate)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        return y_pred, scores\n",
    "    elif TrainMyClassifierParameters[1] == 'RVM':\n",
    "        # #############################################################################\n",
    "        # Train a RVM classification model\n",
    "        print(\"Fitting the classifier to the training set\")\n",
    "        t0 = time()\n",
    "        param_grid = TrainMyClassifierParameters[0]\n",
    "        clf = OneVsOneClassifier(GridSearchCV(RVC(kernel='rbf',n_iter=1), param_grid))\n",
    "        clf.fit(XEstimate, YEstimate)\n",
    "        y_pred = clf.predict(XValidate)\n",
    "        scores = clf.score(XEstimate,YEstimate)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        return y_pred, scores\n",
    "    elif TrainMyClassifierParameters[1] == 'GP':\n",
    "       # #############################################################################\n",
    "        # Train a GP classification model\n",
    "        print(\"Fitting the classifier to the training set\")\n",
    "        t0 = time()\n",
    "        param_grid = TrainMyClassifierParameters[0]['length_scale']\n",
    "        k_rbf = 1 * RBF(length_scale=param_grid)\n",
    "        clf = OneVsOneClassifier(GaussianProcessClassifier(kernel = k_rbf))\n",
    "        clf.fit(X_train_1, y_train_1)\n",
    "        y_pred = clf.predict(XValidate)\n",
    "        scores = clf.score(XEstimate,YEstimate)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        return y_pred, scores\n",
    "    else:\n",
    "        print(\"Incorrect type of algorithm, please use only one of the supported classifiers SVM, RVM, GP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "done in 1.033s\n"
     ]
    }
   ],
   "source": [
    "test = TrainMyClassifier(X_train_1, y_train_1, X_test,TrainMyClassifierParameters('SVM'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyConfusionMatrix Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyConfusionMatrix(Y,YValidate,ClassNames):\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import pandas as pd\n",
    "    c_r = classification_report(YValidate, Y)\n",
    "    c_m = confusion_matrix(YValidate, Y)\n",
    "    a_s = accuracy_score(YValidate, Y)\n",
    "    # labels = ['One','Two','Three','Four','Five'] - This is the format of the labels\n",
    "    labels = ClassNames\n",
    "    df = pd.DataFrame(c_m, dtype='str', index=labels)\n",
    "    df.columns = ClassNames\n",
    "    return c_m, df, a_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[982,  54, 245,  21,  84],\n",
       "        [  4, 294,   2,  20,   0],\n",
       "        [  3,   9, 597,   3,  10],\n",
       "        [  6, 641, 105, 935, 289],\n",
       "        [  5,   2,  51,  21, 617]], dtype=int64),\n",
       "        One  Two Three Four Five\n",
       " One    982   54   245   21   84\n",
       " Two      4  294     2   20    0\n",
       " Three    3    9   597    3   10\n",
       " Four     6  641   105  935  289\n",
       " Five     5    2    51   21  617,\n",
       " 0.685)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyConfusionMatrix(y_test, test[0],['One','Two','Three','Four','Five'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyCrossValidate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "done in 0.985s\n",
      "Fitting the classifier to the training set\n",
      "done in 0.909s\n",
      "Fitting the classifier to the training set\n",
      "done in 7.261s\n",
      "Fitting the classifier to the training set\n",
      "done in 0.940s\n",
      "Fitting the classifier to the training set\n",
      "done in 0.833s\n",
      "Fitting the classifier to the training set\n",
      "done in 6.471s\n",
      "Fitting the classifier to the training set\n",
      "done in 0.931s\n",
      "Fitting the classifier to the training set\n",
      "done in 0.834s\n",
      "Fitting the classifier to the training set\n",
      "done in 6.541s\n",
      "Fitting the classifier to the training set\n",
      "done in 1.000s\n",
      "Fitting the classifier to the training set\n",
      "done in 0.877s\n",
      "Fitting the classifier to the training set\n",
      "done in 6.785s\n",
      "Fitting the classifier to the training set\n",
      "done in 1.014s\n",
      "Fitting the classifier to the training set\n",
      "done in 0.908s\n",
      "Fitting the classifier to the training set\n",
      "done in 6.753s\n",
      "[array([[792,   5,   6,   3,   3],\n",
      "       [  6, 759,   5,  57,   4],\n",
      "       [  7,   3, 739,   6,  24],\n",
      "       [  9,  61,   1, 736,  12],\n",
      "       [  4,   0,  10,  22, 726]], dtype=int64), array([[747,  10,   1,   8,   2],\n",
      "       [  8, 703,   4,  67,   0],\n",
      "       [  7,   4, 774,   2,  14],\n",
      "       [  1,  60,  14, 724,  22],\n",
      "       [  2,   5,  35,  21, 765]], dtype=int64), array([[827,   8,   6,   3,   2],\n",
      "       [  6, 675,   3,  50,   0],\n",
      "       [  2,   4, 737,   5,  16],\n",
      "       [  3,  50,  10, 756,  16],\n",
      "       [  0,   3,  31,  15, 772]], dtype=int64), array([[766,   6,   8,   4,   1],\n",
      "       [ 12, 773,   5,  64,   1],\n",
      "       [  6,   2, 819,   5,  14],\n",
      "       [  2,  53,   6, 671,  16],\n",
      "       [  1,   1,  31,  15, 718]], dtype=int64), array([[779,   1,   4,   7,   1],\n",
      "       [ 12, 724,   2,  59,   1],\n",
      "       [  4,   1, 789,   3,  13],\n",
      "       [  3,  55,   8, 693,  18],\n",
      "       [  2,   5,  38,  21, 757]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "def MyCrossValidate(XTrain,YTrain2,Nf,Algorithm): #Why do we use a YTrain with '2' index?\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    dict = {} \n",
    "    \n",
    "    pca = PCA(n_components=9)\n",
    "    reduced_data = pca.fit_transform(XTrain)\n",
    "    #print reduced_data.shape\n",
    "    kf = KFold(n_splits=Nf)\n",
    "    kf.get_n_splits(XTrain)\n",
    "    EstParameters = []\n",
    "    EstConfMatrices = []\n",
    "    ConfMatrix=[]\n",
    "    YTrain = []\n",
    "    i=0        \n",
    "    for train_index, test_index in kf.split(XTrain):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        XEst1 = XTrain[train_index]\n",
    "        YEst1 = YTrain2[train_index]      \n",
    "        XValid = XTrain[test_index]\n",
    "        YValid = YTrain2[test_index]          \n",
    "        XEst = XEst1[:4000]\n",
    "        YEst = YEst1[:4000]\n",
    "        TrainMyClassifierParameters = []\n",
    "        TrainMyClassifierParameters.append({'C': [1e3], 'gamma': [0.001] })\n",
    "        TrainMyClassifierParameters.append(Algorithm)\n",
    "        y_pred1, scores1 = TrainMyClassifier(XEst,YEst,XValid,TrainMyClassifierParameters)\n",
    "        TrainMyClassifierParameters[0] = {'C': [1e4], 'gamma': [0.01]}\n",
    "        y_pred2, scores2 = TrainMyClassifier(XEst,YEst,XValid,TrainMyClassifierParameters)\n",
    "        TrainMyClassifierParameters[0] = {'C': [1e5], 'gamma': [0.1]}\n",
    "        y_pred3, scores3 = TrainMyClassifier(XEst,YEst,XValid,TrainMyClassifierParameters)\n",
    "        if max(scores1,scores2,scores3)==scores1:\n",
    "            y_pred = y_pred1\n",
    "            dict[i]= {'scores':[scores1,scores2,scores3],'C': [1e3], 'gamma': [0.001]}\n",
    "        elif max(scores1,scores2,scores3)==scores2:\n",
    "            y_pred = y_pred2\n",
    "            dict[i]= {'scores':[scores1,scores2,scores3],'C': [1e4], 'gamma': [0.01]}\n",
    "        elif max(scores1,scores2,scores3)==scores3:\n",
    "            y_pred = y_pred3  \n",
    "            dict[i]= {'scores':[scores1,scores2,scores3],'C': [1e5], 'gamma': [0.1]}\n",
    "        confMatrix = MyConfusionMatrix(y_pred,YValid)\n",
    "        EstConfMatrices.append(confMatrix)\n",
    "#         EstParameters.append(params)\n",
    "        YTrain.append(y_pred)\n",
    "        i=i+1\n",
    "#         y_pred, params = TrainMyClassifier(XEst,YEst,XValid,Algorithm,{'C': [1], 'gamma': [1] })\n",
    "#         confMatrix = MyConfusionMatrix(y_pred,YValid)\n",
    "#         EstConfMatrices.append(confMatrix)\n",
    "#         EstParameters.append(params)\n",
    "#         YTrain.append(y_pred)\n",
    "    np.save(Algorithm+'.npy',dict)\n",
    "    return YTrain,EstParameters, EstConfMatrices,ConfMatrix\n",
    "\n",
    "def MyConfusionMatrix(Y,ClassNames):\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        return confusion_matrix(ClassNames,Y)\n",
    "       \n",
    "YTrain,EstParameters, EstConfMatrices,ConfMatrix = MyCrossValidate(X_train,y_train,5,'SVM')\n",
    "print (EstConfMatrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TestMyClassifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestMyClassifier(XTest, Parameters, EstParameters):\n",
    "    # Do similar to trainmyclassifer but with the data from MyCrossValidation\n",
    "    return YTest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
